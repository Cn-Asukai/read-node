# 数据存储与索引

最简单的数据存储：

>  一个纯文本文件。其每行key-value用逗号分隔（大致像csv文件，忽略转义问题）。每次追加新内容到文件末尾，因此，如果多次更新某个键，旧版本的值不会被覆盖，而是需要查看文件中最后一次出现的键来找到最新的值

这样的存储结构存在一个问题：

如果日志文件保存了大量的记录，那么查询性能会非常差。每次想查找一个键，必须从头到尾扫描整个数据库文件来查找键的出现位置。在算法术语中，查找的开销是O(n)

## 索引

## 哈希索引

把每个键映射到数据文件中特定的字节偏移量

## SSTables 和 LSM-Tree

SSTable 是排序字符串表，是主键到地址偏移量的映射

优势：

1. 合并段更加简单，多个段文件中，总有一个最新的段，可以直接使用最新的段

2. 因为是有序的，所以可以使用二分查找，在内存中构建一个稀疏的排序字符串表

3. 一块磁盘中的数据，可以被压缩，节省磁盘空间同时减少 io 带宽占用

![](C:\Users\Administrator\AppData\Roaming\marktext\images\2025-01-24-14-27-14-image.png)

### 构建和维护 SSTables

1. 在内存中构建有序数据结构（平衡树），这个数据结构被称为内存表

2. 当内存表大于某个阈值时，将其作为 SSTable 文件写入磁盘

3. 处理读请求时，先从内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件，以此类推

4. 后台进程周期性合并和压缩段文件

存在一个问题：如果数据库崩溃，最近的写入（内存表）将会丢失，为了解决这个问题，在磁盘上保存单独的日志，每次写入立即追加，该日志文件只需要在崩溃后被使用，每当内存表写入 SSTable 时，对应的日志可以被丢弃

### 性能优化

1. 当查找一个不存在的键时，需要查找内存表，然后查找全部的段文件，为了优化这种访问，存储引擎通常使用布隆过滤器

2. 大小分级（HBase）和分层压缩（LevelDB 和 RocksDB）

## B-trees

B-tree 保留按键排序的 key-value 对，实现高效的查找和区间查询

B-tree 将数据库分解成固定大小的块或页（4KB），页是读写的最小单元

每个页可以使用地址或者位置进行表示，便于让另一个页引用

![](C:\Users\Administrator\AppData\Roaming\marktext\images\2025-01-24-14-50-21-image.png)

B-tree 中一个页所包含的子页引用数量被称为分支因子

要更新B-tree，首先搜索该键所在叶子页，更改该页的值，并将新页覆盖旧页

要增加新键，则要找到其范围包含新键的页，并将其添加到页，如果没用足够的空间容纳新键，则要将页分裂为两个半满的页，并且其父页也要更新来包含分裂之后的新的键范围

### 构建可靠 B-tree

B-tree 底层的写操作是新页覆盖旧页，在复杂情况下会出现问题

同时，原地更新在多线程并发下会出现问题，必须使用锁存器保护树的数据结构，日志结构化通过追加日志实现数据修改，后台合并操作不会影响前端查询。

为了使数据库能从崩溃中恢复，常见的 B-tree 需要支持磁盘上的额外数据结构：预写日志（write-ahead log，WAL），也叫重做日志，每个 B-tree 的修改需要先更新 WAL 然后再修改树本身，当数据库崩溃恢复时，该日志用于恢复 B-tree 到最近一致的状态

### 优化 B-tree

1. 使用写时复制替代原地更新和 WAL。修改的页被写入不太的位置，树中父页的新版本被创建

2. 只保存键的缩略信息（聚簇索引），也称 B+ 树

3. 将相邻叶子页按顺序保存在磁盘上，优化顺序扫描性能，但是这个顺序难以维护

4. 在叶子节点上添加向左和向右的指针，这样就可以顺序扫描键，而不需要跳回父页

5. B-tree 变体，如分形树

## 对比 B-tree 和 LSM-tree

### LSM-tree 的优点

1. B-tree 索引必须至少写两次数据：一次写入预写日志，一次写入树的页本身（甚至可能发生页分裂），由于反复压缩和 SSTable 合并，日志结构索引也会重写多次，但是日志结构具有较低的写放大，所以 LSM-tree 通常能承受比 B-tree 更高的写入吞吐量

2. LSM-tree 可以支持更好地压缩，通常磁盘上的文件比 B-tree 小很多。

### LSM-tree 的缺点

1. 日志结构存储在压缩过程中会干扰读写操作，所以会出现查询响应时间有时会相当高的情况，B-tree 的响应延迟更加具有确定性

2. 写入带宽由初始写入（对段文件的写入）和后台运行的压缩合并线程共享，导致数据库的数据量越大，压缩所需的磁盘带宽越多

3. 如果压缩速率跟不上写入速率，会导致磁盘上未合并的段不断增加，直到磁盘空间不足

## 其他索引结构

### 多列索引

1. 级联索引（复合索引）

2. 多维索引：同时查询多列，通常使用 R-tree 实现

3. 全文搜索和模糊索引

# 数据复制

目的：

使数据在地理位置上更接近用户，从而降低访问延迟

当部分组件出现位障，系统依然可以继续工作，从而提高可用性。

扩展至多台机器以同时提供数据访问服务，从而提高读吞量。 

## 主从复制

1. 指定某一个副本为主副本（或称为主节点）当客户写数据库时，必须将写请求首先发送给主副本，主副本首先将新数据写入本地存储。

2. 其他副本全部称为从副本（或称为从节点）注。主副本把新数据写入本地存储后，然后将数据更改作为复制的日志或更改流发送给所有从副本。每个从副本获得更改日志之后将其应用到本地，且严格保持与主副本相同的写入顺序。

3. 客户端从数据库中读数据，可以在主副本或者从副本上执行查询。再次强调，只有主副本才可以接受写请求；从客户端的角度来看，从副本都是只读的。

## 同步复制和异步复制

同步复制会导致阻塞，无法保证可用性

异步复制会无法保证强一致性

## 配置新的从节点

1. 在某个时间点对主节点的数据副本产生一个致性快照，这样避免长时间锁定整个数据库。

2. 将此快照拷贝到新的从节点

3. 从节点连接到主节点并请求快照点之后所发的数据更改日志。因为在第一步建快照时，快照与系统复制日志的某个确定位置相联，这个位置信息在不同的系统有不同的称呼，如PostgreSQL其称为“logsequence number” （日志序列号），而MySQL将其称为“binlogcoordinates“

4. 获得日志之后，从节点来应用这些快照点之后所有数据变更，这个过程称之为追赶。

## 处理节点失效

### 从节点失效

恢复之后根据最后一笔事务，追赶主节点

### 主节点失效

1. 确认主节点失效。有很多种出错可能性，例如由于系统崩溃，停电，网络问题等。没有万无失的方住能够确切地检测到究竟问题出在哪里，所以大多数系统都采用了基于超时的机制：节点间频繁地互相发生发送心跳存活悄息，如果发现某一个节点在段比较长时间内（例如30s）没有响应，即认为该节点发生失效

2. 选举新的主节点。可以通过选举的方式（超过多数的节点达成共识）来选举新的主节点，或者由之前选定的某控制节点来指定新的主节点。候选节点最好与原主节点的数据差异最小，这样可以最小化数据丢失的风险。

3. 重新配置系统使新主节点生效。客户端现在需要将写请求发送给新的主节点。如果原主节点之后重新上线，可能仍然自认为是主节点，而没有意识到其节点已经达成共识迫使其下台。这时系统要确保原主节点降级为从节点，并认可新的主节点。
